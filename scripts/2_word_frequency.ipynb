{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077e4694",
   "metadata": {},
   "source": [
    "# 2. Script for obtaining word frequencies in comment corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55782b",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0ce651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f84b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nicol\\\\Documents\\\\2021-2022\\\\QMSS\\\\Spring'22\\\\QMSS 5999 Thesis\\\\data\\\\\"\n",
    "\n",
    "# Import comment data\n",
    "reddit_raw = pd.read_csv(path+'comments_reddit_all.csv', index_col=0, dtype={'comment_id': 'str', 'text': 'str'})\n",
    "fb_raw = pd.read_csv(path+'comments_fb_all.csv', index_col=0, dtype={'comment_id': 'str', 'text': 'str'})\n",
    "fb_raw = fb_raw[['comment_id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99dd2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both FB and Reddit data into one DataFrame\n",
    "all_raw = pd.concat([reddit_raw, fb_raw], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a62fedb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gww5drd</td>\n",
       "      <td>ALL MY PLANS ARE GONE NOOOOOOOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gww5jfz</td>\n",
       "      <td>&amp;gt; This means people will no longer be allow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gww68ne</td>\n",
       "      <td>phase 2 lai liao wah shag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gww6icr</td>\n",
       "      <td>Government fucks up and takes it out on the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gww6luf</td>\n",
       "      <td>Gyms also closed till 30th. PepeHands. I just ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                               text\n",
       "0    gww5drd                    ALL MY PLANS ARE GONE NOOOOOOOO\n",
       "1    gww5jfz  &gt; This means people will no longer be allow...\n",
       "2    gww68ne                          phase 2 lai liao wah shag\n",
       "3    gww6icr  Government fucks up and takes it out on the po...\n",
       "4    gww6luf  Gyms also closed till 30th. PepeHands. I just ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15714</th>\n",
       "      <td>10158186215552115</td>\n",
       "      <td>Trying very hard to push that all singaporeans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15715</th>\n",
       "      <td>10158186213932115</td>\n",
       "      <td>Omg. This is real bad. And really bad foresigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15716</th>\n",
       "      <td>10158186213787115</td>\n",
       "      <td>Endemic ma, didnt they know this?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15717</th>\n",
       "      <td>10158186211122115</td>\n",
       "      <td>If healthcare system is overstretched, why you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15718</th>\n",
       "      <td>10158186210967115</td>\n",
       "      <td>Overwhelmed by antivaxxers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              comment_id                                               text\n",
       "15714  10158186215552115  Trying very hard to push that all singaporeans...\n",
       "15715  10158186213932115  Omg. This is real bad. And really bad foresigh...\n",
       "15716  10158186213787115                  Endemic ma, didnt they know this?\n",
       "15717  10158186211122115  If healthcare system is overstretched, why you...\n",
       "15718  10158186210967115                         Overwhelmed by antivaxxers"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15719, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect DataFrame and get dimensions\n",
    "display(all_raw.head())\n",
    "display(all_raw.tail())\n",
    "display(all_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d2db6",
   "metadata": {},
   "source": [
    "## Preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb195e42",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb930262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning text\n",
    "def clean_text_freq(text):\n",
    "    import re\n",
    "    import html\n",
    "    text1 = html.unescape(text) # remove HTML encoded characters\n",
    "    text2 = re.sub(r'â€™', '\\'', text1) # replce â€™ with apostrophe\n",
    "    text3 = re.sub(r'\\n', '', text2) # remove excess line breaks between links\n",
    "    text4 = re.sub(r'\\n', ' ', text3) # replace remaining line breaks with spaces\n",
    "    text5 = re.sub(r'#\\S+', '', text4) # remove hashtags\n",
    "    text6 = re.sub(r'http\\S+', '', text5) # remove links starting with http\n",
    "    text7 = re.sub(r'\\S+\\.com\\S+', '', text6) # remove links not starting with http\n",
    "    text8 = re.sub(r'[^A-Za-z]+', ' ', text7).strip().lower() # remove punctuations and digits \n",
    "    return(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c73f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to DataFrame\n",
    "all_raw['text_clean_freq'] = all_raw.text.apply(clean_text_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fd0495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gww5drd</td>\n",
       "      <td>ALL MY PLANS ARE GONE NOOOOOOOO</td>\n",
       "      <td>all my plans are gone noooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gww5jfz</td>\n",
       "      <td>&amp;gt; This means people will no longer be allow...</td>\n",
       "      <td>this means people will no longer be allowed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gww68ne</td>\n",
       "      <td>phase 2 lai liao wah shag</td>\n",
       "      <td>phase lai liao wah shag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gww6icr</td>\n",
       "      <td>Government fucks up and takes it out on the po...</td>\n",
       "      <td>government fucks up and takes it out on the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gww6luf</td>\n",
       "      <td>Gyms also closed till 30th. PepeHands. I just ...</td>\n",
       "      <td>gyms also closed till th pepehands i just want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                               text  \\\n",
       "0    gww5drd                    ALL MY PLANS ARE GONE NOOOOOOOO   \n",
       "1    gww5jfz  &gt; This means people will no longer be allow...   \n",
       "2    gww68ne                          phase 2 lai liao wah shag   \n",
       "3    gww6icr  Government fucks up and takes it out on the po...   \n",
       "4    gww6luf  Gyms also closed till 30th. PepeHands. I just ...   \n",
       "\n",
       "                                     text_clean_freq  \n",
       "0                    all my plans are gone noooooooo  \n",
       "1  this means people will no longer be allowed to...  \n",
       "2                            phase lai liao wah shag  \n",
       "3  government fucks up and takes it out on the po...  \n",
       "4  gyms also closed till th pepehands i just want...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect DataFrame\n",
    "all_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa526867",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a594fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing stop words\n",
    "def remove_sw(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    sw = set(stopwords.words('English'))\n",
    "    text_filtered = [word for word in text.split() if not word in sw] \n",
    "    text_filtered = ' '.join(text_filtered) \n",
    "    return(text_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22196716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to DataFrame\n",
    "all_raw['text_no_sw'] = all_raw.text_clean_freq.apply(remove_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce7d12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean_freq</th>\n",
       "      <th>text_no_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gww5drd</td>\n",
       "      <td>ALL MY PLANS ARE GONE NOOOOOOOO</td>\n",
       "      <td>all my plans are gone noooooooo</td>\n",
       "      <td>plans gone noooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gww5jfz</td>\n",
       "      <td>&amp;gt; This means people will no longer be allow...</td>\n",
       "      <td>this means people will no longer be allowed to...</td>\n",
       "      <td>means people longer allowed digitally check sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gww68ne</td>\n",
       "      <td>phase 2 lai liao wah shag</td>\n",
       "      <td>phase lai liao wah shag</td>\n",
       "      <td>phase lai liao wah shag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gww6icr</td>\n",
       "      <td>Government fucks up and takes it out on the po...</td>\n",
       "      <td>government fucks up and takes it out on the po...</td>\n",
       "      <td>government fucks takes population changes work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gww6luf</td>\n",
       "      <td>Gyms also closed till 30th. PepeHands. I just ...</td>\n",
       "      <td>gyms also closed till th pepehands i just want...</td>\n",
       "      <td>gyms also closed till th pepehands want rock c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                               text  \\\n",
       "0    gww5drd                    ALL MY PLANS ARE GONE NOOOOOOOO   \n",
       "1    gww5jfz  &gt; This means people will no longer be allow...   \n",
       "2    gww68ne                          phase 2 lai liao wah shag   \n",
       "3    gww6icr  Government fucks up and takes it out on the po...   \n",
       "4    gww6luf  Gyms also closed till 30th. PepeHands. I just ...   \n",
       "\n",
       "                                     text_clean_freq  \\\n",
       "0                    all my plans are gone noooooooo   \n",
       "1  this means people will no longer be allowed to...   \n",
       "2                            phase lai liao wah shag   \n",
       "3  government fucks up and takes it out on the po...   \n",
       "4  gyms also closed till th pepehands i just want...   \n",
       "\n",
       "                                          text_no_sw  \n",
       "0                               plans gone noooooooo  \n",
       "1  means people longer allowed digitally check sc...  \n",
       "2                            phase lai liao wah shag  \n",
       "3  government fucks takes population changes work...  \n",
       "4  gyms also closed till th pepehands want rock c...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect DataFrame\n",
    "all_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e71a6",
   "metadata": {},
   "source": [
    "### Tokenize comment corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647b08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text in DataFrame to a single string\n",
    "all_raw_string = ' '.join(all_raw['text_no_sw']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ea6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209387\n"
     ]
    }
   ],
   "source": [
    "# Tokenise the whole corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens_all = word_tokenize(all_raw_string)\n",
    "print(len(tokens_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df2e69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain tokens not in NLTK's English dictionary (to identify non-English words that need to be parsed/replaced)\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk_words = words.words()\n",
    "tokens_no_eng = [tok for tok in tokens_all if not tok in nltk_words if not wordnet.synsets(tok)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2999250",
   "metadata": {},
   "source": [
    "## Obtain top 1000 tokens by frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2102ca3",
   "metadata": {},
   "source": [
    "### Whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de506e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain top 1000 tokens from the whole corpus\n",
    "from nltk.probability import FreqDist\n",
    "fdist_all = FreqDist(tokens_all)\n",
    "tokens_all_top1000 = fdist_all.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48098bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 2230),\n",
       " ('covid', 1503),\n",
       " ('like', 1417),\n",
       " ('still', 1249),\n",
       " ('cases', 1188),\n",
       " ('vaccinated', 1165),\n",
       " ('get', 1159),\n",
       " ('go', 1107),\n",
       " ('one', 991),\n",
       " ('even', 961),\n",
       " ('time', 888),\n",
       " ('us', 853),\n",
       " ('need', 842),\n",
       " ('think', 828),\n",
       " ('back', 824),\n",
       " ('singapore', 822),\n",
       " ('also', 810),\n",
       " ('going', 767),\n",
       " ('open', 731),\n",
       " ('government', 698)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect top 20 \n",
    "tokens_all_top1000[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1089fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('walk', 40),\n",
       " ('leaving', 40),\n",
       " ('add', 40),\n",
       " ('brain', 40),\n",
       " ('shop', 40),\n",
       " ('city', 40),\n",
       " ('celebrate', 39),\n",
       " ('outdoor', 39),\n",
       " ('achieve', 39),\n",
       " ('leadership', 39),\n",
       " ('thats', 39),\n",
       " ('panic', 39),\n",
       " ('nz', 39),\n",
       " ('steps', 39),\n",
       " ('protected', 39),\n",
       " ('alot', 39),\n",
       " ('mistake', 39),\n",
       " ('efforts', 39),\n",
       " ('manage', 39),\n",
       " ('aug', 39)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect bottom 20\n",
    "tokens_all_top1000[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcfb840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>still</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cases</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  freq\n",
       "0  people  2230\n",
       "1   covid  1503\n",
       "2    like  1417\n",
       "3   still  1249\n",
       "4   cases  1188"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame and inspect\n",
    "tokens_all_top1000_df = pd.DataFrame(tokens_all_top1000, columns=['token', 'freq'])\n",
    "tokens_all_top1000_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a8611c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as CSV\n",
    "tokens_all_top1000_df.to_csv(path+'comments_all_tokens_top1000.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56a3bf",
   "metadata": {},
   "source": [
    "### Non-English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45d15cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain top 1000 non-English tokens\n",
    "from nltk.probability import FreqDist\n",
    "fdist_no_eng = FreqDist(tokens_no_eng)\n",
    "tokens_no_eng_top1000 = fdist_no_eng.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60e7b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cb', 453),\n",
       " ('ktv', 382),\n",
       " ('govt', 372),\n",
       " ('lol', 297),\n",
       " ('ppl', 238),\n",
       " ('gov', 223),\n",
       " ('etc', 220),\n",
       " ('wfh', 166),\n",
       " ('hbl', 155),\n",
       " ('others', 143),\n",
       " ('moh', 138),\n",
       " ('pls', 138),\n",
       " ('mrt', 134),\n",
       " ('mtf', 112),\n",
       " ('ndp', 103),\n",
       " ('hari', 102),\n",
       " ('vax', 100),\n",
       " ('mmtf', 99),\n",
       " ('oyk', 99),\n",
       " ('reddit', 85)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect top 20 \n",
    "tokens_no_eng_top1000[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee9f01",
   "metadata": {},
   "source": [
    "These non-English tokens will guide me in constructing a dictionary to replace these words with their meaning, to allow the sentiment analysis algorithms to better parse the text and to improve the results. \n",
    "\n",
    "Additionally, this list helps me to decide which tokens should be kept:\n",
    "- For instance, 'cb' is a top token but it has multiple meanings in the corpora as it refers to either a swear word ('cb' short for 'chee bye' which is equivalent in vulgarity to the F word), or the Circuit Breaker lockdown restrictions in April 2020 (which the government and citizens have commonly abbreviated into 'CB'). Given the confusion, I will eliminate this specifc token from the list. I will only retain 'cb' if it is part of another token like 'ccb' which definitely refers to the swear phrase ('chao chee bye') and not the restrictions. \n",
    "- I will also not replace tokens which do not have a concise explanation/replacement in the English language, or tokens that are proper nouns.\n",
    "- Internet slang abbreviations e.g. lol, lmao, etc. will not be replaced as they can be captured by VADER.\n",
    "- Tokens with frequency <= 50 will not be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5466dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and export as CSV\n",
    "tokens_no_eng_top1000_df = pd.DataFrame(tokens_no_eng_top1000, columns=['token', 'freq'])\n",
    "tokens_no_eng_top1000_df.to_csv(path+'comments_all_tokens_no_eng_top1000.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4368ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
