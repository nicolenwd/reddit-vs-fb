{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077e4694",
   "metadata": {},
   "source": [
    "# 2. Script for obtaining word frequencies in comment corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55782b",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c0ce651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f84b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nicol\\\\Documents\\\\2021-2022\\\\QMSS\\\\Spring'22\\\\QMSS 5999 Thesis\\\\data\\\\\"\n",
    "\n",
    "# Import comment data\n",
    "reddit_raw = pd.read_csv(path+'comments_reddit_all.csv', index_col=0, dtype={'comment_id': 'str', 'text': 'str'})\n",
    "fb_raw = pd.read_csv(path+'comments_fb_all.csv', index_col=0, dtype={'comment_id': 'str', 'text': 'str'})\n",
    "fb_raw = fb_raw[['comment_id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e66accb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both FB and Reddit data into one DataFrame\n",
    "all_raw = pd.concat([reddit_raw, fb_raw], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a62fedb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gww5drd</td>\n",
       "      <td>ALL MY PLANS ARE GONE NOOOOOOOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gww5jfz</td>\n",
       "      <td>&amp;gt; This means people will no longer be allow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gww68ne</td>\n",
       "      <td>phase 2 lai liao wah shag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gww6icr</td>\n",
       "      <td>Government fucks up and takes it out on the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gww6luf</td>\n",
       "      <td>Gyms also closed till 30th. PepeHands. I just ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                               text\n",
       "0    gww5drd                    ALL MY PLANS ARE GONE NOOOOOOOO\n",
       "1    gww5jfz  &gt; This means people will no longer be allow...\n",
       "2    gww68ne                          phase 2 lai liao wah shag\n",
       "3    gww6icr  Government fucks up and takes it out on the po...\n",
       "4    gww6luf  Gyms also closed till 30th. PepeHands. I just ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15943</th>\n",
       "      <td>10158807617032934</td>\n",
       "      <td>Top fan\\nTimothy Tan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15944</th>\n",
       "      <td>10158807627202934</td>\n",
       "      <td>ðŸ‘€ðŸ‘€ðŸ‘€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15945</th>\n",
       "      <td>10158807627087934</td>\n",
       "      <td>ðŸ™„ðŸ™„ðŸ™„ðŸ™„ðŸ™„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15946</th>\n",
       "      <td>10158807433227934</td>\n",
       "      <td>Hmmâ€¦ THOT AH ONG SAID WE BEGINNING TO SEE LIGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15947</th>\n",
       "      <td>10158806329392934</td>\n",
       "      <td>Eh, i thought GKY said the numbers are stable ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              comment_id                                               text\n",
       "15943  10158807617032934                               Top fan\\nTimothy Tan\n",
       "15944  10158807627202934                                                ðŸ‘€ðŸ‘€ðŸ‘€\n",
       "15945  10158807627087934                                              ðŸ™„ðŸ™„ðŸ™„ðŸ™„ðŸ™„\n",
       "15946  10158807433227934  Hmmâ€¦ THOT AH ONG SAID WE BEGINNING TO SEE LIGH...\n",
       "15947  10158806329392934  Eh, i thought GKY said the numbers are stable ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15948, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect DataFrame and get dimensions\n",
    "display(all_raw.head())\n",
    "display(all_raw.tail())\n",
    "display(all_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d2db6",
   "metadata": {},
   "source": [
    "## Preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb195e42",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb930262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning text\n",
    "def clean_text_freq(text):\n",
    "    import re\n",
    "    import html\n",
    "    text1 = html.unescape(text) # remove HTML encoded characters\n",
    "    text2 = re.sub(r'Ã¢â‚¬â„¢', '\\'', text1) # replce Ã¢â‚¬â„¢ with apostrophe\n",
    "    text3 = re.sub(r'\\n', '', text2) # remove excess line breaks between links\n",
    "    text4 = re.sub(r'\\n', ' ', text3) # replace remaining line breaks with spaces\n",
    "    text5 = re.sub(r'#\\S+', '', text4) # remove hashtags\n",
    "    text6 = re.sub(r'http\\S+', '', text5) # remove links starting with http\n",
    "    text7 = re.sub(r'\\S+\\.com\\S+', '', text6) # remove links not starting with http\n",
    "    text8 = re.sub(r'[^A-Za-z]+', ' ', text7).strip().lower() # remove punctuations and digits \n",
    "    return(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c73f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to DataFrame\n",
    "all_raw['text_clean_freq'] = all_raw.text.apply(clean_text_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fd0495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gww5drd</td>\n",
       "      <td>ALL MY PLANS ARE GONE NOOOOOOOO</td>\n",
       "      <td>all my plans are gone noooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gww5jfz</td>\n",
       "      <td>&amp;gt; This means people will no longer be allow...</td>\n",
       "      <td>this means people will no longer be allowed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gww68ne</td>\n",
       "      <td>phase 2 lai liao wah shag</td>\n",
       "      <td>phase lai liao wah shag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gww6icr</td>\n",
       "      <td>Government fucks up and takes it out on the po...</td>\n",
       "      <td>government fucks up and takes it out on the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gww6luf</td>\n",
       "      <td>Gyms also closed till 30th. PepeHands. I just ...</td>\n",
       "      <td>gyms also closed till th pepehands i just want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                               text  \\\n",
       "0    gww5drd                    ALL MY PLANS ARE GONE NOOOOOOOO   \n",
       "1    gww5jfz  &gt; This means people will no longer be allow...   \n",
       "2    gww68ne                          phase 2 lai liao wah shag   \n",
       "3    gww6icr  Government fucks up and takes it out on the po...   \n",
       "4    gww6luf  Gyms also closed till 30th. PepeHands. I just ...   \n",
       "\n",
       "                                     text_clean_freq  \n",
       "0                    all my plans are gone noooooooo  \n",
       "1  this means people will no longer be allowed to...  \n",
       "2                            phase lai liao wah shag  \n",
       "3  government fucks up and takes it out on the po...  \n",
       "4  gyms also closed till th pepehands i just want...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect DataFrame\n",
    "all_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa526867",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a594fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing stop words\n",
    "def remove_sw(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    sw = set(stopwords.words('English'))\n",
    "    text_filtered = [word for word in text.split() if not word in sw] \n",
    "    text_filtered = ' '.join(text_filtered) \n",
    "    return(text_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22196716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to DataFrame\n",
    "all_raw['text_no_sw'] = all_raw.text_clean_freq.apply(remove_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce7d12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean_freq</th>\n",
       "      <th>text_no_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gww5drd</td>\n",
       "      <td>ALL MY PLANS ARE GONE NOOOOOOOO</td>\n",
       "      <td>all my plans are gone noooooooo</td>\n",
       "      <td>plans gone noooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gww5jfz</td>\n",
       "      <td>&amp;gt; This means people will no longer be allow...</td>\n",
       "      <td>this means people will no longer be allowed to...</td>\n",
       "      <td>means people longer allowed digitally check sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gww68ne</td>\n",
       "      <td>phase 2 lai liao wah shag</td>\n",
       "      <td>phase lai liao wah shag</td>\n",
       "      <td>phase lai liao wah shag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gww6icr</td>\n",
       "      <td>Government fucks up and takes it out on the po...</td>\n",
       "      <td>government fucks up and takes it out on the po...</td>\n",
       "      <td>government fucks takes population changes work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gww6luf</td>\n",
       "      <td>Gyms also closed till 30th. PepeHands. I just ...</td>\n",
       "      <td>gyms also closed till th pepehands i just want...</td>\n",
       "      <td>gyms also closed till th pepehands want rock c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                               text  \\\n",
       "0    gww5drd                    ALL MY PLANS ARE GONE NOOOOOOOO   \n",
       "1    gww5jfz  &gt; This means people will no longer be allow...   \n",
       "2    gww68ne                          phase 2 lai liao wah shag   \n",
       "3    gww6icr  Government fucks up and takes it out on the po...   \n",
       "4    gww6luf  Gyms also closed till 30th. PepeHands. I just ...   \n",
       "\n",
       "                                     text_clean_freq  \\\n",
       "0                    all my plans are gone noooooooo   \n",
       "1  this means people will no longer be allowed to...   \n",
       "2                            phase lai liao wah shag   \n",
       "3  government fucks up and takes it out on the po...   \n",
       "4  gyms also closed till th pepehands i just want...   \n",
       "\n",
       "                                          text_no_sw  \n",
       "0                               plans gone noooooooo  \n",
       "1  means people longer allowed digitally check sc...  \n",
       "2                            phase lai liao wah shag  \n",
       "3  government fucks takes population changes work...  \n",
       "4  gyms also closed till th pepehands want rock c...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect DataFrame\n",
    "all_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e71a6",
   "metadata": {},
   "source": [
    "### Tokenize comment corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647b08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text in DataFrame to a single string\n",
    "all_raw_string = ' '.join(all_raw['text_no_sw']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ea6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise the whole corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens_all = word_tokenize(all_raw_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2e69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain tokens not in NLTK's English dictionary (to identify non-English words that need to be parsed/replaced)\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk_words = words.words()\n",
    "tokens_no_eng = [tok for tok in tokens_all if not tok in nltk_words if not wordnet.synsets(tok)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2999250",
   "metadata": {},
   "source": [
    "## Obtain top 1000 tokens by frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2102ca3",
   "metadata": {},
   "source": [
    "### Whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de506e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain top 1000 tokens from the whole corpus\n",
    "from nltk.probability import FreqDist\n",
    "fdist_all = FreqDist(tokens_all)\n",
    "tokens_all_top1000 = fdist_all.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48098bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 2310),\n",
       " ('covid', 1640),\n",
       " ('like', 1446),\n",
       " ('still', 1269),\n",
       " ('cases', 1268),\n",
       " ('vaccinated', 1212),\n",
       " ('get', 1171),\n",
       " ('go', 1129),\n",
       " ('one', 1022),\n",
       " ('even', 973),\n",
       " ('time', 920),\n",
       " ('also', 900),\n",
       " ('singapore', 894),\n",
       " ('need', 883),\n",
       " ('us', 870),\n",
       " ('back', 838),\n",
       " ('think', 834),\n",
       " ('going', 784),\n",
       " ('open', 752),\n",
       " ('government', 715)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect top 20 \n",
    "tokens_all_top1000[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcfb840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>still</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cases</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  freq\n",
       "0  people  2310\n",
       "1   covid  1640\n",
       "2    like  1446\n",
       "3   still  1269\n",
       "4   cases  1268"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame and inspect\n",
    "tokens_all_top1000_df = pd.DataFrame(tokens_all_top1000, columns=['token', 'freq'])\n",
    "tokens_all_top1000_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8611c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as CSV\n",
    "tokens_all_top1000_df.to_csv(path+'comments_all_tokens_top1000.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56a3bf",
   "metadata": {},
   "source": [
    "### Non-English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d15cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain top 1000 non-English tokens\n",
    "from nltk.probability import FreqDist\n",
    "fdist_no_eng = FreqDist(tokens_no_eng)\n",
    "tokens_no_eng_top1000 = fdist_no_eng.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60e7b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cb', 456),\n",
       " ('ktv', 384),\n",
       " ('govt', 375),\n",
       " ('lol', 298),\n",
       " ('ppl', 244),\n",
       " ('etc', 224),\n",
       " ('gov', 224),\n",
       " ('moh', 222),\n",
       " ('wfh', 168),\n",
       " ('hbl', 159),\n",
       " ('others', 148),\n",
       " ('pls', 141),\n",
       " ('mrt', 136),\n",
       " ('pre', 128),\n",
       " ('mtf', 125),\n",
       " ('vax', 105),\n",
       " ('mmtf', 104),\n",
       " ('oyk', 103),\n",
       " ('ndp', 103),\n",
       " ('hari', 102)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect top 20 \n",
    "tokens_no_eng_top1000[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee9f01",
   "metadata": {},
   "source": [
    "These non-English tokens will guide me in constructing a dictionary to replace these words with their meaning, to allow the sentiment analysis algorithms to better parse the text and to improve the results. \n",
    "\n",
    "Additionally, this list helps me to decide which tokens should be kept:\n",
    "- For instance, 'cb' is a top token but it has multiple meanings in the corpora as it refers to either a swear word ('cb' short for 'chee bye' which is equivalent in vulgarity to the F word), or the Circuit Breaker lockdown restrictions in April 2020 (which the government and citizens have commonly abbreviated into 'CB'). Given the confusion, I will eliminate this specifc token from the list. I will only retain 'cb' if it is part of another token like 'ccb' which definitely refers to the swear phrase ('chao chee bye') and not the restrictions. \n",
    "- I will also not replace tokens which do not have a concise explanation/replacement in the English language, or tokens that are proper nouns.\n",
    "- Internet slang abbreviations e.g. lol, lmao, etc. will not be replaced as they can be captured by VADER.\n",
    "- Tokens with frequency <= 50 will not be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5466dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and export as CSV\n",
    "tokens_no_eng_top1000_df = pd.DataFrame(tokens_no_eng_top1000, columns=['token', 'freq'])\n",
    "tokens_no_eng_top1000_df.to_csv(path+'comments_all_tokens_no_eng_top1000.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4368ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
